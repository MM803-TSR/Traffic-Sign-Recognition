{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf.app.flags.DEFINE_string('train_data_dir', '/Users/Olivier/c399project/GTSRB/Train',\n",
    "                           \"\"\"Path to the Traffic data directory.\"\"\")\n",
    "tf.app.flags.DEFINE_string('test_data_dir', '/Users/Olivier/c399project/GTSRB/Test',\n",
    "                           \"\"\"Path to save training info.\"\"\")\n",
    "tf.app.flags.DEFINE_string('train_dir', '/Users/Olivier/c399project',\n",
    "                           \"\"\"Path to save training info.\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "FLAGS = tf.app.flags.FLAGS\n",
    "train_data_dir = FLAGS.train_data_dir\n",
    "test_data_dir = FLAGS.test_data_dir\n",
    "train_dir = FLAGS.train_dir\n",
    "\n",
    "size = 32,32\n",
    "classes = 43\n",
    "val_size = 12630\n",
    "batch_size = 100\n",
    "max_steps = 2000\n",
    "\n",
    "X = tf.placeholder(tf.float32, name = \"input\")\n",
    "T = tf.placeholder(tf.float32)\n",
    "target_Class = tf.placeholder(tf.int32)\n",
    "is_training = tf.placeholder(tf.bool, [], name='is_training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_and_decode(filename_queue):\n",
    "    reader = tf.TFRecordReader()\n",
    "    _, serialized_example = reader.read(filename_queue)\n",
    "    features = tf.parse_single_example(\n",
    "        serialized_example,\n",
    "        features={\n",
    "            'image/encoded': tf.FixedLenFeature([], tf.string),\n",
    "            'image/class/label': tf.FixedLenFeature([], tf.int64),\n",
    "        })\n",
    "    label = tf.cast(features['image/class/label'], tf.int32) - 1\n",
    "    \n",
    "    reshaped_image = tf.image.decode_jpeg(features['image/encoded'], channels = 3)\n",
    "    method=0\n",
    "    resized_image = tf.image.resize_images(reshaped_image, (size[0], size[1]), method = 0)\n",
    "    return resized_image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def distorted_inputs(batch_size, num_epochs):\n",
    "\n",
    "    subset = \"train\"\n",
    "    \n",
    "    tf_record_pattern = os.path.join(FLAGS.train_dir + '/GTSRB', '%s-*' % subset)\n",
    "    data_files = tf.gfile.Glob(tf_record_pattern)\n",
    "    \n",
    "    \n",
    "    filename_queue = tf.train.string_input_producer(data_files, shuffle=True)\n",
    "    image, label = read_and_decode(filename_queue)\n",
    "    distorted_image = tf.image.random_brightness(image, max_delta=63)\n",
    "    distorted_image = tf.image.random_contrast(distorted_image, lower=0.2, upper=1.8)\n",
    "    normalized_image = tf.image.per_image_whitening(distorted_image)\n",
    "    \n",
    "    # Shuffle the examples and collect them into batch_size batches.\n",
    "    # (Internally uses a RandomShuffleQueue.)\n",
    "    # We run this in two threads to avoid being a bottleneck.\n",
    "    \n",
    "    images, sparse_labels = tf.train.shuffle_batch(\n",
    "        [normalized_image, label], batch_size=batch_size, num_threads=2,\n",
    "        capacity=1000 + 3 * batch_size,\n",
    "        # Ensures a minimum amount of shuffling of examples.\n",
    "        min_after_dequeue=1000)\n",
    "    return images, sparse_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def inputs(batch_size, num_epochs):\n",
    "\n",
    "    subset = \"validation\"\n",
    "    \n",
    "    tf_record_pattern = os.path.join(FLAGS.train_dir + '/GTSRB', '%s-*' % subset)\n",
    "    data_files = tf.gfile.Glob(tf_record_pattern)\n",
    "    \n",
    "    filename_queue = tf.train.string_input_producer(data_files, shuffle=False, capacity=1)#num_epochs=num_epochs)\n",
    "    image, label = read_and_decode(filename_queue)\n",
    "    normalized_image = tf.image.per_image_whitening(image)\n",
    "    \n",
    "    images, sparse_labels = tf.train.batch(\n",
    "        [normalized_image, label], batch_size=batch_size, num_threads=2,\n",
    "        capacity=1000 + 3 * batch_size)\n",
    "    return images, sparse_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weight_variable(shape):\n",
    "    #He et al\n",
    "    stddev=math.sqrt(2.0/np.prod(shape[:3]))\n",
    "    #print stddev\n",
    "    initial = tf.random_normal(shape, stddev=stddev)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.01, shape=shape)\n",
    "    return tf.Variable(initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filters_conv1 = 16\n",
    "dropout = 0.50\n",
    "\n",
    "#Conv 1\n",
    "W_conv1 = weight_variable([3, 3, 3, filters_conv1])\n",
    "b_conv1 = bias_variable([filters_conv1])\n",
    "conv1 = tf.nn.conv2d(X, W_conv1, strides =[1, 1, 1, 1], padding = 'SAME')\n",
    "\n",
    "#Relu 1\n",
    "relu1 = tf.nn.relu(conv1 + b_conv1)\n",
    "\n",
    "#Dropout first layer\n",
    "#if is_training is not None:\n",
    "#     relu1 = tf.nn.dropout(relu1, dropout)\n",
    "\n",
    "#Batch norm 1\n",
    "batch_norm1 = tf.contrib.layers.batch_norm(relu1, is_training= is_training, updates_collections= None)\n",
    "\n",
    "#Max pool 1\n",
    "max_pool1 = tf.nn.max_pool(batch_norm1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "filters_conv2 = 32\n",
    "\n",
    "#Conv 2\n",
    "W_conv2 = weight_variable([3, 3, filters_conv1, filters_conv2])\n",
    "b_conv2 = bias_variable([filters_conv2])\n",
    "conv2 = tf.nn.conv2d(max_pool1, W_conv2, strides =[1,1,1,1], padding = 'SAME')\n",
    "\n",
    "#Relu 2\n",
    "relu2 = tf.nn.relu(conv2 + b_conv2)\n",
    "\n",
    "#Dropout second layer\n",
    "#if is_training is not None:\n",
    "#     relu2 = tf.nn.dropout(relu2, dropout)\n",
    "\n",
    "#Batch norm 2\n",
    "batch_norm2 = tf.contrib.layers.batch_norm(relu2, is_training= is_training, updates_collections= None)\n",
    "\n",
    "#Max pool 2\n",
    "max_pool2 = tf.nn.max_pool(batch_norm2, ksize=[1,2,2,1], strides =[1,2,2,1],padding='SAME')\n",
    "\n",
    "filters_conv3 = 64\n",
    "\n",
    "#Conv 3\n",
    "W_conv3 = weight_variable([3, 3, filters_conv2, filters_conv3])\n",
    "b_conv3 = bias_variable([filters_conv3])\n",
    "conv3 = tf.nn.conv2d(max_pool2, W_conv3, strides =[1,1,1,1], padding = 'SAME')\n",
    "\n",
    "#Relu 3\n",
    "relu3 = tf.nn.relu(conv3 + b_conv3)\n",
    "\n",
    "#Dropout last layer\n",
    "#if is_training is not None:\n",
    "#     relu3 = tf.nn.dropout(relu3, dropout)\n",
    "\n",
    "#Batch norm 3\n",
    "batch_norm3 = tf.contrib.layers.batch_norm(relu3, is_training= is_training, updates_collections= None)\n",
    "\n",
    "#Max pool 3\n",
    "max_pool3 = tf.nn.max_pool(batch_norm3, ksize=[1,2,2,1], strides =[1,2,2,1],padding='SAME')\n",
    "\n",
    "\n",
    "#Local \n",
    "filters_fc1 =  classes\n",
    "\n",
    "\n",
    "#Reduced to 3 x 3\n",
    "W_fc1 = weight_variable([4 * 4 * filters_conv3, filters_fc1])\n",
    "b_fc1 = bias_variable([filters_fc1])\n",
    "\n",
    "max_pool3_flat = tf.reshape(max_pool3, [-1, 4 * 4 * filters_conv3])\n",
    "fc1 = tf.matmul(max_pool3_flat,W_fc1) + b_fc1 #593, 10\n",
    "\n",
    "#Y=tf.nn.softmax(fc1, name=\"output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "T = tf.cast(tf.one_hot(indices = target_Class, depth = classes, on_value=1, off_value=0,axis=-1),tf.float32)\n",
    "#to_sum = (T * tf.log(Y + 1e-10))\n",
    "#cross_entropy = tf.reduce_mean(-tf.reduce_sum(to_sum, reduction_indices=1))\n",
    "\n",
    "regularizers = (tf.nn.l2_loss(W_fc1) + tf.nn.l2_loss(b_fc1)) \n",
    "hinge_loss = tf.contrib.losses.hinge_loss(fc1, T)\n",
    "\n",
    "\n",
    "final_loss = tf.reduce_mean(tf.cast(hinge_loss + regularizers * 5e-4, tf.float32))\n",
    "#final_loss = tf.reduce_mean(tf.cast(hinge_loss, tf.float32))\n",
    "loss_summary = tf.scalar_summary('final_loss', final_loss)\n",
    "\n",
    "#loss_summary = tf.scalar_summary('cross_entropy', cross_entropy)\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(fc1,1), tf.argmax(T,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "accuracy_summary = tf.scalar_summary('accuracy', accuracy)\n",
    "\n",
    "train_step = tf.train.AdamOptimizer(5e-3).minimize(final_loss)#1e-4\n",
    "saver = tf.train.Saver()\n",
    "summary_op = tf.merge_summary([loss_summary, accuracy_summary])\n",
    "summary_writer = tf.train.SummaryWriter(os.path.join(train_dir, 'Log'), sess.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_input = distorted_inputs(batch_size,1000)\n",
    "val_input = inputs(12630,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Thread(Thread-5, started daemon 4685041664)>,\n",
       " <Thread(Thread-6, started daemon 4689248256)>,\n",
       " <Thread(Thread-7, started daemon 4693454848)>,\n",
       " <Thread(Thread-8, started daemon 4697661440)>,\n",
       " <Thread(Thread-9, started daemon 4701868032)>,\n",
       " <Thread(Thread-10, started daemon 4706074624)>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(tf.initialize_all_variables())\n",
    "sess.run(tf.initialize_local_variables())\n",
    "tf.train.start_queue_runners(sess=sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmark (No Regularization lr = 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:  0 . Loss:  3.7536\n",
      "Step:  100 . Loss:  3.24122\n",
      "Step:  200 . Loss:  2.89084\n",
      "Step:  300 . Loss:  2.68005\n",
      "Step:  400 . Loss:  2.4579\n",
      "Step:  500 . Loss:  2.36892\n",
      "Step:  600 . Loss:  2.24055\n",
      "Step:  700 . Loss:  2.088\n",
      "Step:  800 . Loss:  1.81157\n",
      "Step:  900 . Loss:  1.72236\n",
      "Step:  1000 . Loss:  1.49664\n",
      "Step:  1100 . Loss:  1.42123\n",
      "Step:  1200 . Loss:  1.24232\n",
      "Step:  1300 . Loss:  1.08342\n",
      "Step:  1400 . Loss:  1.07183\n",
      "Step:  1500 . Loss:  0.929261\n",
      "Step:  1600 . Loss:  0.801677\n",
      "Step:  1700 . Loss:  0.737931\n",
      "Step:  1800 . Loss:  0.721035\n",
      "Step:  1900 . Loss:  0.58069\n"
     ]
    }
   ],
   "source": [
    "for i in range(max_steps):\n",
    "    \n",
    "    train_batch = sess.run(train_input)\n",
    "    summary_str, _ = sess.run([summary_op, train_step], feed_dict={\n",
    "            X:train_batch[0], target_Class:train_batch[1], is_training: True})\n",
    "    summary_writer.add_summary(summary_str, i)    \n",
    "    if i % 100 == 0:\n",
    "        loss = sess.run(cross_entropy,feed_dict={X:train_batch[0], target_Class:train_batch[1], is_training: False})\n",
    "        print 'Step: ',i,'. Loss: ',loss\n",
    "        #if loss < 0.05 :\n",
    "        #    saver.save(sess, os.path.join(train_dir, 'Save/model.ckpt'))\n",
    "        #    break\n",
    "    if i % 1000 == 0 or (i + 1) == max_steps:\n",
    "        saver.save(sess, os.path.join(train_dir, 'Save/model.ckpt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.859778\n"
     ]
    }
   ],
   "source": [
    "val_batch = sess.run(val_input)\n",
    "acc = sess.run(accuracy, feed_dict={X: val_batch[0], target_Class:val_batch[1], is_training: False})\n",
    "print acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# No Regularization (lr = 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:  0 . Loss:  3.31417\n",
      "Step:  100 . Loss:  2.61827\n",
      "Step:  200 . Loss:  2.22712\n",
      "Step:  300 . Loss:  1.97276\n",
      "Step:  400 . Loss:  1.78759\n",
      "Step:  500 . Loss:  1.35738\n",
      "Step:  600 . Loss:  1.32299\n",
      "Step:  700 . Loss:  0.759078\n",
      "Step:  800 . Loss:  0.616521\n",
      "Step:  900 . Loss:  0.464506\n",
      "Step:  1000 . Loss:  0.449309\n",
      "Step:  1100 . Loss:  0.302529\n",
      "Step:  1200 . Loss:  0.233699\n",
      "Step:  1300 . Loss:  0.234065\n",
      "Step:  1400 . Loss:  0.23437\n",
      "Step:  1500 . Loss:  0.0814788\n",
      "Step:  1600 . Loss:  0.0802397\n",
      "Step:  1700 . Loss:  0.0812941\n",
      "Step:  1800 . Loss:  0.0619496\n",
      "Step:  1900 . Loss:  0.0243947\n"
     ]
    }
   ],
   "source": [
    "for i in range(max_steps):\n",
    "    \n",
    "    train_batch = sess.run(train_input)\n",
    "    summary_str, _ = sess.run([summary_op, train_step], feed_dict={\n",
    "            X:train_batch[0], target_Class:train_batch[1], is_training: True})\n",
    "    summary_writer.add_summary(summary_str, i)    \n",
    "    if i % 100 == 0:\n",
    "        loss = sess.run(cross_entropy,feed_dict={X:train_batch[0], target_Class:train_batch[1], is_training: False})\n",
    "        print 'Step: ',i,'. Loss: ',loss\n",
    "        #if loss < 0.05 :\n",
    "        #    saver.save(sess, os.path.join(train_dir, 'Save/model.ckpt'))\n",
    "        #    break\n",
    "    if i % 1000 == 0 or (i + 1) == max_steps:\n",
    "        saver.save(sess, os.path.join(train_dir, 'Save/model.ckpt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.926207\n"
     ]
    }
   ],
   "source": [
    "val_batch = sess.run(val_input)\n",
    "acc = sess.run(accuracy, feed_dict={X: val_batch[0], target_Class:val_batch[1], is_training: False})\n",
    "print acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attempt 2, No Regularization (lr = 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:  0 . Loss:  3.20159\n",
      "Step:  100 . Loss:  2.25153\n",
      "Step:  200 . Loss:  2.35871\n",
      "Step:  300 . Loss:  2.20054\n",
      "Step:  400 . Loss:  1.99434\n",
      "Step:  500 . Loss:  1.84756\n",
      "Step:  600 . Loss:  1.29041\n",
      "Step:  700 . Loss:  1.20245\n",
      "Step:  800 . Loss:  1.05675\n",
      "Step:  900 . Loss:  0.837313\n",
      "Step:  1000 . Loss:  0.691346\n",
      "Step:  1100 . Loss:  0.406833\n",
      "Step:  1200 . Loss:  0.380381\n",
      "Step:  1300 . Loss:  0.274885\n",
      "Step:  1400 . Loss:  0.185056\n",
      "Step:  1500 . Loss:  0.112368\n",
      "Step:  1600 . Loss:  0.111585\n",
      "Step:  1700 . Loss:  0.0823438\n",
      "Step:  1800 . Loss:  0.0914605\n",
      "Step:  1900 . Loss:  0.0601741\n"
     ]
    }
   ],
   "source": [
    "for i in range(max_steps):\n",
    "    \n",
    "    train_batch = sess.run(train_input)\n",
    "    summary_str, _ = sess.run([summary_op, train_step], feed_dict={\n",
    "            X:train_batch[0], target_Class:train_batch[1], is_training: True})\n",
    "    summary_writer.add_summary(summary_str, i)    \n",
    "    if i % 100 == 0:\n",
    "        loss = sess.run(cross_entropy,feed_dict={X:train_batch[0], target_Class:train_batch[1], is_training: False})\n",
    "        print 'Step: ',i,'. Loss: ',loss\n",
    "        #if loss < 0.05 :\n",
    "        #    saver.save(sess, os.path.join(train_dir, 'Save/model.ckpt'))\n",
    "        #    break\n",
    "    if i % 1000 == 0 or (i + 1) == max_steps:\n",
    "        saver.save(sess, os.path.join(train_dir, 'Save/model.ckpt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.930325\n"
     ]
    }
   ],
   "source": [
    "val_batch = sess.run(val_input)\n",
    "acc = sess.run(accuracy, feed_dict={X: val_batch[0], target_Class:val_batch[1], is_training: False})\n",
    "print acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# No Regularization (lr = 1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(max_steps):\n",
    "    \n",
    "    train_batch = sess.run(train_input)\n",
    "    summary_str, _ = sess.run([summary_op, train_step], feed_dict={\n",
    "            X:train_batch[0], target_Class:train_batch[1], is_training: True})\n",
    "    summary_writer.add_summary(summary_str, i)    \n",
    "    if i % 100 == 0:\n",
    "        loss = sess.run(cross_entropy,feed_dict={X:train_batch[0], target_Class:train_batch[1], is_training: False})\n",
    "        print 'Step: ',i,'. Loss: ',loss\n",
    "        #if loss < 0.05 :\n",
    "        #    saver.save(sess, os.path.join(train_dir, 'Save/model.ckpt'))\n",
    "        #    break\n",
    "    if i % 1000 == 0 or (i + 1) == max_steps:\n",
    "        saver.save(sess, os.path.join(train_dir, 'Save/model.ckpt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dropout = 0.5 (all three layers), lr = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:  0 . Loss:  4.91831\n",
      "Step:  100 . Loss:  4.0078\n",
      "Step:  200 . Loss:  3.33719\n",
      "Step:  300 . Loss:  2.56912\n",
      "Step:  400 . Loss:  2.55848\n",
      "Step:  500 . Loss:  1.80295\n",
      "Step:  600 . Loss:  1.70359\n",
      "Step:  700 . Loss:  1.49646\n",
      "Step:  800 . Loss:  1.28805\n",
      "Step:  900 . Loss:  1.46846\n",
      "Step:  1000 . Loss:  1.37136\n",
      "Step:  1100 . Loss:  1.39738\n",
      "Step:  1200 . Loss:  1.23874\n",
      "Step:  1300 . Loss:  1.18244\n",
      "Step:  1400 . Loss:  1.08036\n",
      "Step:  1500 . Loss:  1.18825\n",
      "Step:  1600 . Loss:  1.02413\n",
      "Step:  1700 . Loss:  1.07764\n",
      "Step:  1800 . Loss:  0.924771\n",
      "Step:  1900 . Loss:  0.979659\n"
     ]
    }
   ],
   "source": [
    "for i in range(max_steps):\n",
    "    \n",
    "    train_batch = sess.run(train_input)\n",
    "    summary_str, _ = sess.run([summary_op, train_step], feed_dict={\n",
    "            X:train_batch[0], target_Class:train_batch[1], is_training: True})\n",
    "    summary_writer.add_summary(summary_str, i)    \n",
    "    if i % 100 == 0:\n",
    "        loss = sess.run(cross_entropy,feed_dict={X:train_batch[0], target_Class:train_batch[1], is_training: False})\n",
    "        print 'Step: ',i,'. Loss: ',loss\n",
    "        if loss < 0.05 :\n",
    "            saver.save(sess, os.path.join(train_dir, 'Save/model.ckpt'))\n",
    "            break\n",
    "    if i % 1000 == 0 or (i + 1) == max_steps:\n",
    "        saver.save(sess, os.path.join(train_dir, 'Save/model.ckpt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.649248\n"
     ]
    }
   ],
   "source": [
    "val_batch = sess.run(val_input)\n",
    "acc = sess.run(accuracy, feed_dict={X: val_batch[0], target_Class:val_batch[1], is_training: False})\n",
    "print acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dropout = 0.75 (all three layers), lr = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:  0 . Loss:  3.91304\n",
      "Step:  100 . Loss:  3.51453\n",
      "Step:  200 . Loss:  2.88305\n",
      "Step:  300 . Loss:  2.23679\n",
      "Step:  400 . Loss:  1.88749\n",
      "Step:  500 . Loss:  1.65306\n",
      "Step:  600 . Loss:  1.47248\n",
      "Step:  700 . Loss:  1.26717\n",
      "Step:  800 . Loss:  1.05781\n",
      "Step:  900 . Loss:  1.04965\n",
      "Step:  1000 . Loss:  1.19831\n",
      "Step:  1100 . Loss:  0.841833\n",
      "Step:  1200 . Loss:  0.960767\n",
      "Step:  1300 . Loss:  0.834251\n",
      "Step:  1400 . Loss:  0.822843\n",
      "Step:  1500 . Loss:  0.728744\n",
      "Step:  1600 . Loss:  0.565386\n",
      "Step:  1700 . Loss:  0.641309\n",
      "Step:  1800 . Loss:  0.582814\n",
      "Step:  1900 . Loss:  0.552345\n"
     ]
    }
   ],
   "source": [
    "for i in range(max_steps):\n",
    "    \n",
    "    train_batch = sess.run(train_input)\n",
    "    summary_str, _ = sess.run([summary_op, train_step], feed_dict={\n",
    "            X:train_batch[0], target_Class:train_batch[1], is_training: True})\n",
    "    summary_writer.add_summary(summary_str, i)    \n",
    "    if i % 100 == 0:\n",
    "        loss = sess.run(cross_entropy,feed_dict={X:train_batch[0], target_Class:train_batch[1], is_training: False})\n",
    "        print 'Step: ',i,'. Loss: ',loss\n",
    "        if loss < 0.05 :\n",
    "            saver.save(sess, os.path.join(train_dir, 'Save/model.ckpt'))\n",
    "            break\n",
    "    if i % 1000 == 0 or (i + 1) == max_steps:\n",
    "        saver.save(sess, os.path.join(train_dir, 'Save/model.ckpt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.782344\n"
     ]
    }
   ],
   "source": [
    "val_batch = sess.run(val_input)\n",
    "acc = sess.run(accuracy, feed_dict={X: val_batch[0], target_Class:val_batch[1], is_training: False})\n",
    "print acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dropout = 0.75 (all three layers), lr = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:  0 . Loss:  3.60022\n",
      "Step:  100 . Loss:  1.82001\n",
      "Step:  200 . Loss:  1.18199\n",
      "Step:  300 . Loss:  1.04527\n",
      "Step:  400 . Loss:  1.06241\n",
      "Step:  500 . Loss:  0.593265\n",
      "Step:  600 . Loss:  0.591066\n",
      "Step:  700 . Loss:  0.466514\n",
      "Step:  800 . Loss:  0.304028\n",
      "Step:  900 . Loss:  0.26783\n",
      "Step:  1000 . Loss:  0.236989\n",
      "Step:  1100 . Loss:  0.185212\n",
      "Step:  1200 . Loss:  0.126802\n",
      "Step:  1300 . Loss:  0.135735\n",
      "Step:  1400 . Loss:  0.0924672\n",
      "Step:  1500 . Loss:  0.115159\n",
      "Step:  1600 . Loss:  0.0792972\n",
      "Step:  1700 . Loss:  0.107193\n",
      "Step:  1800 . Loss:  0.153237\n",
      "Step:  1900 . Loss:  0.0378849\n"
     ]
    }
   ],
   "source": [
    "for i in range(max_steps):\n",
    "    \n",
    "    train_batch = sess.run(train_input)\n",
    "    summary_str, _ = sess.run([summary_op, train_step], feed_dict={\n",
    "            X:train_batch[0], target_Class:train_batch[1], is_training: True})\n",
    "    summary_writer.add_summary(summary_str, i)    \n",
    "    if i % 100 == 0:\n",
    "        loss = sess.run(cross_entropy,feed_dict={X:train_batch[0], target_Class:train_batch[1], is_training: False})\n",
    "        print 'Step: ',i,'. Loss: ',loss\n",
    "        if loss < 0.05 :\n",
    "            saver.save(sess, os.path.join(train_dir, 'Save/model.ckpt'))\n",
    "            break\n",
    "    if i % 1000 == 0 or (i + 1) == max_steps:\n",
    "        saver.save(sess, os.path.join(train_dir, 'Save/model.ckpt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.903642\n"
     ]
    }
   ],
   "source": [
    "val_batch = sess.run(val_input)\n",
    "acc = sess.run(accuracy, feed_dict={X: val_batch[0], target_Class:val_batch[1], is_training: False})\n",
    "print acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dropout = 0.75 (all three layers), lr = 5e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:  0 . Loss:  4.82204\n",
      "Step:  100 . Loss:  1.87974\n",
      "Step:  200 . Loss:  2.05365\n",
      "Step:  300 . Loss:  0.886548\n",
      "Step:  400 . Loss:  1.32419\n",
      "Step:  500 . Loss:  0.831887\n",
      "Step:  600 . Loss:  0.64722\n",
      "Step:  700 . Loss:  0.105297\n",
      "Step:  800 . Loss:  0.366433\n",
      "Step:  900 . Loss:  0.393805\n",
      "Step:  1000 . Loss:  0.849938\n",
      "Step:  1100 . Loss:  0.192251\n",
      "Step:  1200 . Loss:  0.458831\n",
      "Step:  1300 . Loss:  0.529752\n",
      "Step:  1400 . Loss:  0.170316\n",
      "Step:  1500 . Loss:  0.183271\n",
      "Step:  1600 . Loss:  0.223511\n",
      "Step:  1700 . Loss:  0.118869\n",
      "Step:  1800 . Loss:  0.282904\n",
      "Step:  1900 . Loss:  0.304339\n"
     ]
    }
   ],
   "source": [
    "for i in range(max_steps):\n",
    "    \n",
    "    train_batch = sess.run(train_input)\n",
    "    summary_str, _ = sess.run([summary_op, train_step], feed_dict={\n",
    "            X:train_batch[0], target_Class:train_batch[1], is_training: True})\n",
    "    summary_writer.add_summary(summary_str, i)    \n",
    "    if i % 100 == 0:\n",
    "        loss = sess.run(cross_entropy,feed_dict={X:train_batch[0], target_Class:train_batch[1], is_training: False})\n",
    "        print 'Step: ',i,'. Loss: ',loss\n",
    "        if loss < 0.05 :\n",
    "            saver.save(sess, os.path.join(train_dir, 'Save/model.ckpt'))\n",
    "            break\n",
    "    if i % 1000 == 0 or (i + 1) == max_steps:\n",
    "        saver.save(sess, os.path.join(train_dir, 'Save/model.ckpt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.890024\n"
     ]
    }
   ],
   "source": [
    "val_batch = sess.run(val_input)\n",
    "acc = sess.run(accuracy, feed_dict={X: val_batch[0], target_Class:val_batch[1], is_training: False})\n",
    "print acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dropout = 0.75 (only first layer), lr = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:  0 . Loss:  3.83697\n",
      "Step:  100 . Loss:  3.14492\n",
      "Step:  200 . Loss:  3.01874\n",
      "Step:  300 . Loss:  2.72159\n",
      "Step:  400 . Loss:  2.43664\n",
      "Step:  500 . Loss:  2.25104\n",
      "Step:  600 . Loss:  1.85186\n",
      "Step:  700 . Loss:  1.72528\n",
      "Step:  800 . Loss:  1.7278\n",
      "Step:  900 . Loss:  1.46431\n",
      "Step:  1000 . Loss:  1.34019\n",
      "Step:  1100 . Loss:  1.12854\n",
      "Step:  1200 . Loss:  1.09007\n",
      "Step:  1300 . Loss:  1.05348\n",
      "Step:  1400 . Loss:  0.960848\n",
      "Step:  1500 . Loss:  0.754366\n",
      "Step:  1600 . Loss:  0.619626\n",
      "Step:  1700 . Loss:  0.687439\n",
      "Step:  1800 . Loss:  0.523773\n",
      "Step:  1900 . Loss:  0.50295\n"
     ]
    }
   ],
   "source": [
    "for i in range(max_steps):\n",
    "    \n",
    "    train_batch = sess.run(train_input)\n",
    "    summary_str, _ = sess.run([summary_op, train_step], feed_dict={\n",
    "            X:train_batch[0], target_Class:train_batch[1], is_training: True})\n",
    "    summary_writer.add_summary(summary_str, i)    \n",
    "    if i % 100 == 0:\n",
    "        loss = sess.run(cross_entropy,feed_dict={X:train_batch[0], target_Class:train_batch[1], is_training: False})\n",
    "        print 'Step: ',i,'. Loss: ',loss\n",
    "        if loss < 0.05 :\n",
    "            saver.save(sess, os.path.join(train_dir, 'Save/model.ckpt'))\n",
    "            break\n",
    "    if i % 1000 == 0 or (i + 1) == max_steps:\n",
    "        saver.save(sess, os.path.join(train_dir, 'Save/model.ckpt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.868725\n"
     ]
    }
   ],
   "source": [
    "val_batch = sess.run(val_input)\n",
    "acc = sess.run(accuracy, feed_dict={X: val_batch[0], target_Class:val_batch[1], is_training: False})\n",
    "print acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dropout = 0.75 (first layer), lr = 5e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:  0 . Loss:  3.36925\n",
      "Step:  100 . Loss:  2.3945\n",
      "Step:  200 . Loss:  2.05912\n",
      "Step:  300 . Loss:  1.89554\n",
      "Step:  400 . Loss:  1.65967\n",
      "Step:  500 . Loss:  1.54105\n",
      "Step:  600 . Loss:  1.24334\n",
      "Step:  700 . Loss:  1.25968\n",
      "Step:  800 . Loss:  0.912741\n",
      "Step:  900 . Loss:  0.807883\n",
      "Step:  1000 . Loss:  0.694755\n",
      "Step:  1100 . Loss:  0.515607\n",
      "Step:  1200 . Loss:  0.355836\n",
      "Step:  1300 . Loss:  0.340719\n",
      "Step:  1400 . Loss:  0.330222\n",
      "Step:  1500 . Loss:  0.304393\n",
      "Step:  1600 . Loss:  0.208659\n",
      "Step:  1700 . Loss:  0.171567\n",
      "Step:  1800 . Loss:  0.155338\n",
      "Step:  1900 . Loss:  0.188009\n"
     ]
    }
   ],
   "source": [
    "for i in range(max_steps):\n",
    "    \n",
    "    train_batch = sess.run(train_input)\n",
    "    summary_str, _ = sess.run([summary_op, train_step], feed_dict={\n",
    "            X:train_batch[0], target_Class:train_batch[1], is_training: True})\n",
    "    summary_writer.add_summary(summary_str, i)    \n",
    "    if i % 100 == 0:\n",
    "        loss = sess.run(cross_entropy,feed_dict={X:train_batch[0], target_Class:train_batch[1], is_training: False})\n",
    "        print 'Step: ',i,'. Loss: ',loss\n",
    "        #if loss < 0.05 :\n",
    "        #    saver.save(sess, os.path.join(train_dir, 'Save/model.ckpt'))\n",
    "        #    break\n",
    "    if i % 1000 == 0 or (i + 1) == max_steps:\n",
    "        saver.save(sess, os.path.join(train_dir, 'Save/model.ckpt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.914489\n"
     ]
    }
   ],
   "source": [
    "val_batch = sess.run(val_input)\n",
    "acc = sess.run(accuracy, feed_dict={X: val_batch[0], target_Class:val_batch[1], is_training: False})\n",
    "print acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dropout = 0.75 (first layer), lr = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:  0 . Loss:  3.0932\n",
      "Step:  100 . Loss:  1.85392\n",
      "Step:  200 . Loss:  1.48162\n",
      "Step:  300 . Loss:  1.38833\n",
      "Step:  400 . Loss:  1.1526\n",
      "Step:  500 . Loss:  0.870631\n",
      "Step:  600 . Loss:  0.738435\n",
      "Step:  700 . Loss:  0.413413\n",
      "Step:  800 . Loss:  0.364456\n",
      "Step:  900 . Loss:  0.300523\n",
      "Step:  1000 . Loss:  0.312692\n",
      "Step:  1100 . Loss:  0.239826\n",
      "Step:  1200 . Loss:  0.197565\n",
      "Step:  1300 . Loss:  0.13111\n",
      "Step:  1400 . Loss:  0.0945244\n",
      "Step:  1500 . Loss:  0.0694274\n",
      "Step:  1600 . Loss:  0.0544139\n",
      "Step:  1700 . Loss:  0.0389439\n",
      "Step:  1800 . Loss:  0.0358317\n",
      "Step:  1900 . Loss:  0.0524417\n"
     ]
    }
   ],
   "source": [
    "for i in range(max_steps):\n",
    "    \n",
    "    train_batch = sess.run(train_input)\n",
    "    summary_str, _ = sess.run([summary_op, train_step], feed_dict={\n",
    "            X:train_batch[0], target_Class:train_batch[1], is_training: True})\n",
    "    summary_writer.add_summary(summary_str, i)    \n",
    "    if i % 100 == 0:\n",
    "        loss = sess.run(cross_entropy,feed_dict={X:train_batch[0], target_Class:train_batch[1], is_training: False})\n",
    "        print 'Step: ',i,'. Loss: ',loss\n",
    "        #if loss < 0.05 :\n",
    "        #    saver.save(sess, os.path.join(train_dir, 'Save/model.ckpt'))\n",
    "        #    break\n",
    "    if i % 1000 == 0 or (i + 1) == max_steps:\n",
    "        saver.save(sess, os.path.join(train_dir, 'Save/model.ckpt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.937767\n"
     ]
    }
   ],
   "source": [
    "val_batch = sess.run(val_input)\n",
    "acc = sess.run(accuracy, feed_dict={X: val_batch[0], target_Class:val_batch[1], is_training: False})\n",
    "print acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ATTEMPT 2, Dropout = 0.75 (first layer), lr = 1e-3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:  0 . Loss:  3.24065\n",
      "Step:  100 . Loss:  2.30655\n",
      "Step:  200 . Loss:  2.10576\n",
      "Step:  300 . Loss:  1.85185\n",
      "Step:  400 . Loss:  1.36072\n",
      "Step:  500 . Loss:  1.25371\n",
      "Step:  600 . Loss:  0.878236\n",
      "Step:  700 . Loss:  0.633516\n",
      "Step:  800 . Loss:  0.546105\n",
      "Step:  900 . Loss:  0.476141\n",
      "Step:  1000 . Loss:  0.311988\n",
      "Step:  1100 . Loss:  0.284903\n",
      "Step:  1200 . Loss:  0.221223\n",
      "Step:  1300 . Loss:  0.0884746\n",
      "Step:  1400 . Loss:  0.131383\n",
      "Step:  1500 . Loss:  0.105534\n",
      "Step:  1600 . Loss:  0.0514172\n",
      "Step:  1700 . Loss:  0.0387598\n",
      "Step:  1800 . Loss:  0.0319892\n",
      "Step:  1900 . Loss:  0.0649666\n"
     ]
    }
   ],
   "source": [
    "for i in range(max_steps):\n",
    "    \n",
    "    train_batch = sess.run(train_input)\n",
    "    summary_str, _ = sess.run([summary_op, train_step], feed_dict={\n",
    "            X:train_batch[0], target_Class:train_batch[1], is_training: True})\n",
    "    summary_writer.add_summary(summary_str, i)    \n",
    "    if i % 100 == 0:\n",
    "        loss = sess.run(cross_entropy,feed_dict={X:train_batch[0], target_Class:train_batch[1], is_training: False})\n",
    "        print 'Step: ',i,'. Loss: ',loss\n",
    "        #if loss < 0.05 :\n",
    "        #    saver.save(sess, os.path.join(train_dir, 'Save/model.ckpt'))\n",
    "        #    break\n",
    "    if i % 1000 == 0 or (i + 1) == max_steps:\n",
    "        saver.save(sess, os.path.join(train_dir, 'Save/model.ckpt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.921615\n"
     ]
    }
   ],
   "source": [
    "val_batch = sess.run(val_input)\n",
    "acc = sess.run(accuracy, feed_dict={X: val_batch[0], target_Class:val_batch[1], is_training: False})\n",
    "print acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dropout = 0.75 (first layer), lr = 1e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:  0 . Loss:  8.32478\n",
      "Step:  100 . Loss:  12.2061\n",
      "Step:  200 . Loss:  3.7615\n",
      "Step:  300 . Loss:  3.09903\n",
      "Step:  400 . Loss:  1.20554\n",
      "Step:  500 . Loss:  1.49422\n",
      "Step:  600 . Loss:  1.76923\n",
      "Step:  700 . Loss:  0.981331\n",
      "Step:  800 . Loss:  0.677316\n",
      "Step:  900 . Loss:  0.278588\n",
      "Step:  1000 . Loss:  0.156135\n",
      "Step:  1100 . Loss:  0.489705\n",
      "Step:  1200 . Loss:  0.196344\n",
      "Step:  1300 . Loss:  0.557647\n",
      "Step:  1400 . Loss:  0.0768923\n",
      "Step:  1500 . Loss:  1.59089\n",
      "Step:  1600 . Loss:  0.0368046\n",
      "Step:  1700 . Loss:  0.637939\n",
      "Step:  1800 . Loss:  0.403258\n",
      "Step:  1900 . Loss:  0.276448\n"
     ]
    }
   ],
   "source": [
    "for i in range(max_steps):\n",
    "    \n",
    "    train_batch = sess.run(train_input)\n",
    "    summary_str, _ = sess.run([summary_op, train_step], feed_dict={\n",
    "            X:train_batch[0], target_Class:train_batch[1], is_training: True})\n",
    "    summary_writer.add_summary(summary_str, i)    \n",
    "    if i % 100 == 0:\n",
    "        loss = sess.run(cross_entropy,feed_dict={X:train_batch[0], target_Class:train_batch[1], is_training: False})\n",
    "        print 'Step: ',i,'. Loss: ',loss\n",
    "        #if loss < 0.05 :\n",
    "        #    saver.save(sess, os.path.join(train_dir, 'Save/model.ckpt'))\n",
    "        #    break\n",
    "    if i % 1000 == 0 or (i + 1) == max_steps:\n",
    "        saver.save(sess, os.path.join(train_dir, 'Save/model.ckpt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.921061\n"
     ]
    }
   ],
   "source": [
    "val_batch = sess.run(val_input)\n",
    "acc = sess.run(accuracy, feed_dict={X: val_batch[0], target_Class:val_batch[1], is_training: False})\n",
    "print acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dropout = 0.75 (first layer), lr = 5e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:  0 . Loss:  4.16728\n",
      "Step:  100 . Loss:  3.32084\n",
      "Step:  200 . Loss:  1.48668\n",
      "Step:  300 . Loss:  0.863478\n",
      "Step:  400 . Loss:  0.540382\n",
      "Step:  500 . Loss:  0.0998179\n",
      "Step:  600 . Loss:  0.46698\n",
      "Step:  700 . Loss:  0.132601\n",
      "Step:  800 . Loss:  0.218672\n",
      "Step:  900 . Loss:  0.347927\n",
      "Step:  1000 . Loss:  0.156757\n",
      "Step:  1100 . Loss:  0.169492\n",
      "Step:  1200 . Loss:  0.143467\n",
      "Step:  1300 . Loss:  0.177369\n",
      "Step:  1400 . Loss:  0.115933\n",
      "Step:  1500 . Loss:  0.0236459\n",
      "Step:  1600 . Loss:  0.0464055\n",
      "Step:  1700 . Loss:  0.0610753\n",
      "Step:  1800 . Loss:  0.0366021\n",
      "Step:  1900 . Loss:  0.00118205\n"
     ]
    }
   ],
   "source": [
    "for i in range(max_steps):\n",
    "    \n",
    "    train_batch = sess.run(train_input)\n",
    "    summary_str, _ = sess.run([summary_op, train_step], feed_dict={\n",
    "            X:train_batch[0], target_Class:train_batch[1], is_training: True})\n",
    "    summary_writer.add_summary(summary_str, i)    \n",
    "    if i % 100 == 0:\n",
    "        loss = sess.run(cross_entropy,feed_dict={X:train_batch[0], target_Class:train_batch[1], is_training: False})\n",
    "        print 'Step: ',i,'. Loss: ',loss\n",
    "        #if loss < 0.05 :\n",
    "        #    saver.save(sess, os.path.join(train_dir, 'Save/model.ckpt'))\n",
    "        #    break\n",
    "    if i % 1000 == 0 or (i + 1) == max_steps:\n",
    "        saver.save(sess, os.path.join(train_dir, 'Save/model.ckpt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.896912\n"
     ]
    }
   ],
   "source": [
    "val_batch = sess.run(val_input)\n",
    "acc = sess.run(accuracy, feed_dict={X: val_batch[0], target_Class:val_batch[1], is_training: False})\n",
    "print acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dropout = 0.50 (first layer), lr = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:  0 . Loss:  3.2954\n",
      "Step:  100 . Loss:  1.36617\n",
      "Step:  200 . Loss:  1.03301\n",
      "Step:  300 . Loss:  0.946421\n",
      "Step:  400 . Loss:  0.659636\n",
      "Step:  500 . Loss:  0.613479\n",
      "Step:  600 . Loss:  0.506634\n",
      "Step:  700 . Loss:  0.373168\n",
      "Step:  800 . Loss:  0.295519\n",
      "Step:  900 . Loss:  0.199702\n",
      "Step:  1000 . Loss:  0.23973\n",
      "Step:  1100 . Loss:  0.208186\n",
      "Step:  1200 . Loss:  0.0853827\n",
      "Step:  1300 . Loss:  0.105373\n",
      "Step:  1400 . Loss:  0.111231\n",
      "Step:  1500 . Loss:  0.0798168\n",
      "Step:  1600 . Loss:  0.0409815\n",
      "Step:  1700 . Loss:  0.0751088\n",
      "Step:  1800 . Loss:  0.0463233\n",
      "Step:  1900 . Loss:  0.0466431\n"
     ]
    }
   ],
   "source": [
    "for i in range(max_steps):\n",
    "    \n",
    "    train_batch = sess.run(train_input)\n",
    "    summary_str, _ = sess.run([summary_op, train_step], feed_dict={\n",
    "            X:train_batch[0], target_Class:train_batch[1], is_training: True})\n",
    "    summary_writer.add_summary(summary_str, i)    \n",
    "    if i % 100 == 0:\n",
    "        loss = sess.run(cross_entropy,feed_dict={X:train_batch[0], target_Class:train_batch[1], is_training: False})\n",
    "        print 'Step: ',i,'. Loss: ',loss\n",
    "        #if loss < 0.05 :\n",
    "        #    saver.save(sess, os.path.join(train_dir, 'Save/model.ckpt'))\n",
    "        #    break\n",
    "    if i % 1000 == 0 or (i + 1) == max_steps:\n",
    "        saver.save(sess, os.path.join(train_dir, 'Save/model.ckpt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.914727\n"
     ]
    }
   ],
   "source": [
    "val_batch = sess.run(val_input)\n",
    "acc = sess.run(accuracy, feed_dict={X: val_batch[0], target_Class:val_batch[1], is_training: False})\n",
    "print acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dropout = 0.50 (first layer), lr = 5e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:  0 . Loss:  6.62296\n",
      "Step:  100 . Loss:  5.79374\n",
      "Step:  200 . Loss:  1.21926\n",
      "Step:  300 . Loss:  1.59369\n",
      "Step:  400 . Loss:  1.14089\n",
      "Step:  500 . Loss:  1.37028\n",
      "Step:  600 . Loss:  0.845161\n",
      "Step:  700 . Loss:  0.564346\n",
      "Step:  800 . Loss:  0.198681\n",
      "Step:  900 . Loss:  0.0883338\n",
      "Step:  1000 . Loss:  0.265645\n",
      "Step:  1100 . Loss:  0.534242\n",
      "Step:  1200 . Loss:  0.00857698\n",
      "Step:  1300 . Loss:  0.179123\n",
      "Step:  1400 . Loss:  0.146268\n",
      "Step:  1500 . Loss:  0.139928\n",
      "Step:  1600 . Loss:  0.134172\n",
      "Step:  1700 . Loss:  0.153779\n",
      "Step:  1800 . Loss:  0.0746156\n",
      "Step:  1900 . Loss:  0.19611\n"
     ]
    }
   ],
   "source": [
    "for i in range(max_steps):\n",
    "    \n",
    "    train_batch = sess.run(train_input)\n",
    "    summary_str, _ = sess.run([summary_op, train_step], feed_dict={\n",
    "            X:train_batch[0], target_Class:train_batch[1], is_training: True})\n",
    "    summary_writer.add_summary(summary_str, i)    \n",
    "    if i % 100 == 0:\n",
    "        loss = sess.run(cross_entropy,feed_dict={X:train_batch[0], target_Class:train_batch[1], is_training: False})\n",
    "        print 'Step: ',i,'. Loss: ',loss\n",
    "        #if loss < 0.05 :\n",
    "        #    saver.save(sess, os.path.join(train_dir, 'Save/model.ckpt'))\n",
    "        #    break\n",
    "    if i % 1000 == 0 or (i + 1) == max_steps:\n",
    "        saver.save(sess, os.path.join(train_dir, 'Save/model.ckpt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.894299\n"
     ]
    }
   ],
   "source": [
    "val_batch = sess.run(val_input)\n",
    "acc = sess.run(accuracy, feed_dict={X: val_batch[0], target_Class:val_batch[1], is_training: False})\n",
    "print acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dropout = 0.25 (first layer), lr = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:  0 . Loss:  3.84739\n",
      "Step:  100 . Loss:  2.60637\n",
      "Step:  200 . Loss:  1.21422\n",
      "Step:  300 . Loss:  0.614812\n",
      "Step:  400 . Loss:  0.647092\n",
      "Step:  500 . Loss:  0.431192\n",
      "Step:  600 . Loss:  0.382036\n",
      "Step:  700 . Loss:  0.245916\n",
      "Step:  800 . Loss:  0.202527\n",
      "Step:  900 . Loss:  0.19261\n",
      "Step:  1000 . Loss:  0.224916\n",
      "Step:  1100 . Loss:  0.136206\n",
      "Step:  1200 . Loss:  0.152422\n",
      "Step:  1300 . Loss:  0.0749793\n",
      "Step:  1400 . Loss:  0.140265\n",
      "Step:  1500 . Loss:  0.0913039\n",
      "Step:  1600 . Loss:  0.186984\n",
      "Step:  1700 . Loss:  0.12937\n",
      "Step:  1800 . Loss:  0.102233\n",
      "Step:  1900 . Loss:  0.0457983\n"
     ]
    }
   ],
   "source": [
    "for i in range(max_steps):\n",
    "    \n",
    "    train_batch = sess.run(train_input)\n",
    "    summary_str, _ = sess.run([summary_op, train_step], feed_dict={\n",
    "            X:train_batch[0], target_Class:train_batch[1], is_training: True})\n",
    "    summary_writer.add_summary(summary_str, i)    \n",
    "    if i % 100 == 0:\n",
    "        loss = sess.run(cross_entropy,feed_dict={X:train_batch[0], target_Class:train_batch[1], is_training: False})\n",
    "        print 'Step: ',i,'. Loss: ',loss\n",
    "        #if loss < 0.05 :\n",
    "        #    saver.save(sess, os.path.join(train_dir, 'Save/model.ckpt'))\n",
    "        #    break\n",
    "    if i % 1000 == 0 or (i + 1) == max_steps:\n",
    "        saver.save(sess, os.path.join(train_dir, 'Save/model.ckpt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.887965\n"
     ]
    }
   ],
   "source": [
    "val_batch = sess.run(val_input)\n",
    "acc = sess.run(accuracy, feed_dict={X: val_batch[0], target_Class:val_batch[1], is_training: False})\n",
    "print acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dropout = 0.25 (first layer), lr = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:  0 . Loss:  4.56221\n",
      "Step:  100 . Loss:  3.50385\n",
      "Step:  200 . Loss:  2.99552\n",
      "Step:  300 . Loss:  2.43411\n",
      "Step:  400 . Loss:  2.09392\n",
      "Step:  500 . Loss:  1.53512\n",
      "Step:  600 . Loss:  1.65774\n",
      "Step:  700 . Loss:  1.52918\n",
      "Step:  800 . Loss:  1.34618\n",
      "Step:  900 . Loss:  1.13438\n",
      "Step:  1000 . Loss:  1.24701\n",
      "Step:  1100 . Loss:  1.23941\n",
      "Step:  1200 . Loss:  1.00211\n",
      "Step:  1300 . Loss:  0.92557\n",
      "Step:  1400 . Loss:  0.743873\n",
      "Step:  1500 . Loss:  0.84613\n",
      "Step:  1600 . Loss:  0.752264\n",
      "Step:  1700 . Loss:  0.75734\n",
      "Step:  1800 . Loss:  0.641819\n",
      "Step:  1900 . Loss:  0.720194\n"
     ]
    }
   ],
   "source": [
    "for i in range(max_steps):\n",
    "    \n",
    "    train_batch = sess.run(train_input)\n",
    "    summary_str, _ = sess.run([summary_op, train_step], feed_dict={\n",
    "            X:train_batch[0], target_Class:train_batch[1], is_training: True})\n",
    "    summary_writer.add_summary(summary_str, i)    \n",
    "    if i % 100 == 0:\n",
    "        loss = sess.run(cross_entropy,feed_dict={X:train_batch[0], target_Class:train_batch[1], is_training: False})\n",
    "        print 'Step: ',i,'. Loss: ',loss\n",
    "        #if loss < 0.05 :\n",
    "        #    saver.save(sess, os.path.join(train_dir, 'Save/model.ckpt'))\n",
    "        #    break\n",
    "    if i % 1000 == 0 or (i + 1) == max_steps:\n",
    "        saver.save(sess, os.path.join(train_dir, 'Save/model.ckpt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.750515\n"
     ]
    }
   ],
   "source": [
    "val_batch = sess.run(val_input)\n",
    "acc = sess.run(accuracy, feed_dict={X: val_batch[0], target_Class:val_batch[1], is_training: False})\n",
    "print acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dropout = 0.25 (all three layers), lr = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:  0 . Loss:  16.1139\n",
      "Step:  100 . Loss:  11.2872\n",
      "Step:  200 . Loss:  6.98185\n",
      "Step:  300 . Loss:  5.0678\n",
      "Step:  400 . Loss:  3.36569\n",
      "Step:  500 . Loss:  2.26278\n",
      "Step:  600 . Loss:  2.70454\n",
      "Step:  700 . Loss:  2.27804\n",
      "Step:  800 . Loss:  1.48459\n",
      "Step:  900 . Loss:  1.36311\n",
      "Step:  1000 . Loss:  1.67648\n",
      "Step:  1100 . Loss:  1.11311\n",
      "Step:  1200 . Loss:  0.99523\n",
      "Step:  1300 . Loss:  1.28798\n",
      "Step:  1400 . Loss:  1.08535\n",
      "Step:  1500 . Loss:  1.07099\n",
      "Step:  1600 . Loss:  0.820302\n",
      "Step:  1700 . Loss:  0.961997\n",
      "Step:  1800 . Loss:  0.967935\n",
      "Step:  1900 . Loss:  0.94755\n"
     ]
    }
   ],
   "source": [
    "for i in range(max_steps):\n",
    "    \n",
    "    train_batch = sess.run(train_input)\n",
    "    summary_str, _ = sess.run([summary_op, train_step], feed_dict={\n",
    "            X:train_batch[0], target_Class:train_batch[1], is_training: True})\n",
    "    summary_writer.add_summary(summary_str, i)    \n",
    "    if i % 100 == 0:\n",
    "        loss = sess.run(cross_entropy,feed_dict={X:train_batch[0], target_Class:train_batch[1], is_training: False})\n",
    "        print 'Step: ',i,'. Loss: ',loss\n",
    "        #if loss < 0.05 :\n",
    "        #    saver.save(sess, os.path.join(train_dir, 'Save/model.ckpt'))\n",
    "        #    break\n",
    "    if i % 1000 == 0 or (i + 1) == max_steps:\n",
    "        saver.save(sess, os.path.join(train_dir, 'Save/model.ckpt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.648219\n"
     ]
    }
   ],
   "source": [
    "val_batch = sess.run(val_input)\n",
    "acc = sess.run(accuracy, feed_dict={X: val_batch[0], target_Class:val_batch[1], is_training: False})\n",
    "print acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dropout = 0.75 (last layer), lr = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:  0 . Loss:  3.12127\n",
      "Step:  100 . Loss:  2.09219\n",
      "Step:  200 . Loss:  2.14728\n",
      "Step:  300 . Loss:  1.93018\n",
      "Step:  400 . Loss:  1.55527\n",
      "Step:  500 . Loss:  1.32356\n",
      "Step:  600 . Loss:  1.21193\n",
      "Step:  700 . Loss:  0.739841\n",
      "Step:  800 . Loss:  0.639243\n",
      "Step:  900 . Loss:  0.510116\n",
      "Step:  1000 . Loss:  0.407085\n",
      "Step:  1100 . Loss:  0.226974\n",
      "Step:  1200 . Loss:  0.242082\n",
      "Step:  1300 . Loss:  0.139449\n",
      "Step:  1400 . Loss:  0.119541\n",
      "Step:  1500 . Loss:  0.066762\n",
      "Step:  1600 . Loss:  0.0982869\n",
      "Step:  1700 . Loss:  0.130275\n",
      "Step:  1800 . Loss:  0.0612288\n",
      "Step:  1900 . Loss:  0.0268217\n"
     ]
    }
   ],
   "source": [
    "for i in range(max_steps):\n",
    "    \n",
    "    train_batch = sess.run(train_input)\n",
    "    summary_str, _ = sess.run([summary_op, train_step], feed_dict={\n",
    "            X:train_batch[0], target_Class:train_batch[1], is_training: True})\n",
    "    summary_writer.add_summary(summary_str, i)    \n",
    "    if i % 100 == 0:\n",
    "        loss = sess.run(cross_entropy,feed_dict={X:train_batch[0], target_Class:train_batch[1], is_training: False})\n",
    "        print 'Step: ',i,'. Loss: ',loss\n",
    "        #if loss < 0.05 :\n",
    "        #    saver.save(sess, os.path.join(train_dir, 'Save/model.ckpt'))\n",
    "        #    break\n",
    "    if i % 1000 == 0 or (i + 1) == max_steps:\n",
    "        saver.save(sess, os.path.join(train_dir, 'Save/model.ckpt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.911322\n"
     ]
    }
   ],
   "source": [
    "val_batch = sess.run(val_input)\n",
    "acc = sess.run(accuracy, feed_dict={X: val_batch[0], target_Class:val_batch[1], is_training: False})\n",
    "print acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dropout = 0.75 (middle layer), lr = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:  0 . Loss:  3.24211\n",
      "Step:  100 . Loss:  1.96572\n",
      "Step:  200 . Loss:  1.7286\n",
      "Step:  300 . Loss:  1.34055\n",
      "Step:  400 . Loss:  1.22073\n",
      "Step:  500 . Loss:  0.868452\n",
      "Step:  600 . Loss:  0.745769\n",
      "Step:  700 . Loss:  0.669053\n",
      "Step:  800 . Loss:  0.446787\n",
      "Step:  900 . Loss:  0.400223\n",
      "Step:  1000 . Loss:  0.411238\n",
      "Step:  1100 . Loss:  0.271472\n",
      "Step:  1200 . Loss:  0.237348\n",
      "Step:  1300 . Loss:  0.124074\n",
      "Step:  1400 . Loss:  0.127163\n",
      "Step:  1500 . Loss:  0.113435\n",
      "Step:  1600 . Loss:  0.0457504\n",
      "Step:  1700 . Loss:  0.0612575\n",
      "Step:  1800 . Loss:  0.063899\n",
      "Step:  1900 . Loss:  0.0323914\n"
     ]
    }
   ],
   "source": [
    "for i in range(max_steps):\n",
    "    \n",
    "    train_batch = sess.run(train_input)\n",
    "    summary_str, _ = sess.run([summary_op, train_step], feed_dict={\n",
    "            X:train_batch[0], target_Class:train_batch[1], is_training: True})\n",
    "    summary_writer.add_summary(summary_str, i)    \n",
    "    if i % 100 == 0:\n",
    "        loss = sess.run(cross_entropy,feed_dict={X:train_batch[0], target_Class:train_batch[1], is_training: False})\n",
    "        print 'Step: ',i,'. Loss: ',loss\n",
    "        #if loss < 0.05 :\n",
    "        #    saver.save(sess, os.path.join(train_dir, 'Save/model.ckpt'))\n",
    "        #    break\n",
    "    if i % 1000 == 0 or (i + 1) == max_steps:\n",
    "        saver.save(sess, os.path.join(train_dir, 'Save/model.ckpt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.908393\n"
     ]
    }
   ],
   "source": [
    "val_batch = sess.run(val_input)\n",
    "acc = sess.run(accuracy, feed_dict={X: val_batch[0], target_Class:val_batch[1], is_training: False})\n",
    "print acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dropout = 0.9 (first layer), lr = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:  0 . Loss:  3.19643\n",
      "Step:  100 . Loss:  2.20663\n",
      "Step:  200 . Loss:  1.98418\n",
      "Step:  300 . Loss:  1.56505\n",
      "Step:  400 . Loss:  1.3687\n",
      "Step:  500 . Loss:  1.14797\n",
      "Step:  600 . Loss:  0.909471\n",
      "Step:  700 . Loss:  0.677546\n",
      "Step:  800 . Loss:  0.650981\n",
      "Step:  900 . Loss:  0.492434\n",
      "Step:  1000 . Loss:  0.416482\n",
      "Step:  1100 . Loss:  0.245484\n",
      "Step:  1200 . Loss:  0.183636\n",
      "Step:  1300 . Loss:  0.127822\n",
      "Step:  1400 . Loss:  0.10856\n",
      "Step:  1500 . Loss:  0.0702929\n",
      "Step:  1600 . Loss:  0.105716\n",
      "Step:  1700 . Loss:  0.0922665\n",
      "Step:  1800 . Loss:  0.0544483\n",
      "Step:  1900 . Loss:  0.0239642\n"
     ]
    }
   ],
   "source": [
    "for i in range(max_steps):\n",
    "    \n",
    "    train_batch = sess.run(train_input)\n",
    "    summary_str, _ = sess.run([summary_op, train_step], feed_dict={\n",
    "            X:train_batch[0], target_Class:train_batch[1], is_training: True})\n",
    "    summary_writer.add_summary(summary_str, i)    \n",
    "    if i % 100 == 0:\n",
    "        loss = sess.run(cross_entropy,feed_dict={X:train_batch[0], target_Class:train_batch[1], is_training: False})\n",
    "        print 'Step: ',i,'. Loss: ',loss\n",
    "        #if loss < 0.05 :\n",
    "        #    saver.save(sess, os.path.join(train_dir, 'Save/model.ckpt'))\n",
    "        #    break\n",
    "    if i % 1000 == 0 or (i + 1) == max_steps:\n",
    "        saver.save(sess, os.path.join(train_dir, 'Save/model.ckpt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.919319\n"
     ]
    }
   ],
   "source": [
    "val_batch = sess.run(val_input)\n",
    "acc = sess.run(accuracy, feed_dict={X: val_batch[0], target_Class:val_batch[1], is_training: False})\n",
    "print acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dropout = 0.5 (last layer), lr = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:  0 . Loss:  3.55842\n",
      "Step:  100 . Loss:  3.68531\n",
      "Step:  200 . Loss:  3.5714\n",
      "Step:  300 . Loss:  3.63173\n",
      "Step:  400 . Loss:  3.56067\n",
      "Step:  500 . Loss:  3.26847\n",
      "Step:  600 . Loss:  3.30251\n",
      "Step:  700 . Loss:  3.32587\n",
      "Step:  800 . Loss:  3.37492\n",
      "Step:  900 . Loss:  3.10906\n",
      "Step:  1000 . Loss:  3.14536\n",
      "Step:  1100 . Loss:  2.92082\n",
      "Step:  1200 . Loss:  2.97112\n",
      "Step:  1300 . Loss:  2.57476\n",
      "Step:  1400 . Loss:  2.88524\n",
      "Step:  1500 . Loss:  2.95434\n",
      "Step:  1600 . Loss:  3.02012\n",
      "Step:  1700 . Loss:  2.75022\n",
      "Step:  1800 . Loss:  3.07213\n",
      "Step:  1900 . Loss:  2.82448\n"
     ]
    }
   ],
   "source": [
    "for i in range(max_steps):\n",
    "    \n",
    "    train_batch = sess.run(train_input)\n",
    "    summary_str, _ = sess.run([summary_op, train_step], feed_dict={\n",
    "            X:train_batch[0], target_Class:train_batch[1], is_training: True})\n",
    "    summary_writer.add_summary(summary_str, i)    \n",
    "    if i % 100 == 0:\n",
    "        loss = sess.run(cross_entropy,feed_dict={X:train_batch[0], target_Class:train_batch[1], is_training: False})\n",
    "        print 'Step: ',i,'. Loss: ',loss\n",
    "        #if loss < 0.05 :\n",
    "        #    saver.save(sess, os.path.join(train_dir, 'Save/model.ckpt'))\n",
    "        #    break\n",
    "    if i % 1000 == 0 or (i + 1) == max_steps:\n",
    "        saver.save(sess, os.path.join(train_dir, 'Save/model.ckpt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.233017\n"
     ]
    }
   ],
   "source": [
    "val_batch = sess.run(val_input)\n",
    "acc = sess.run(accuracy, feed_dict={X: val_batch[0], target_Class:val_batch[1], is_training: False})\n",
    "print acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dropout = 0.75 (first layer), lr = 1e-3 (4000 steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:  0 . Loss:  3.16996\n",
      "Step:  100 . Loss:  2.23956\n",
      "Step:  200 . Loss:  1.7717\n",
      "Step:  300 . Loss:  1.4637\n",
      "Step:  400 . Loss:  1.603\n",
      "Step:  500 . Loss:  1.00123\n",
      "Step:  600 . Loss:  0.846839\n",
      "Step:  700 . Loss:  0.684138\n",
      "Step:  800 . Loss:  0.697838\n",
      "Step:  900 . Loss:  0.366344\n",
      "Step:  1000 . Loss:  0.26925\n",
      "Step:  1100 . Loss:  0.272609\n",
      "Step:  1200 . Loss:  0.209791\n",
      "Step:  1300 . Loss:  0.126413\n",
      "Step:  1400 . Loss:  0.0723379\n",
      "Step:  1500 . Loss:  0.0670332\n",
      "Step:  1600 . Loss:  0.0669736\n",
      "Step:  1700 . Loss:  0.0647514\n",
      "Step:  1800 . Loss:  0.033221\n",
      "Step:  1900 . Loss:  0.0362971\n",
      "Step:  2000 . Loss:  0.0123967\n",
      "Step:  2100 . Loss:  0.0395519\n",
      "Step:  2200 . Loss:  0.0169982\n",
      "Step:  2300 . Loss:  0.0367263\n",
      "Step:  2400 . Loss:  0.00842539\n",
      "Step:  2500 . Loss:  0.0170316\n",
      "Step:  2600 . Loss:  0.018728\n",
      "Step:  2700 . Loss:  0.00468952\n",
      "Step:  2800 . Loss:  0.0257063\n",
      "Step:  2900 . Loss:  0.0078549\n",
      "Step:  3000 . Loss:  0.0126013\n",
      "Step:  3100 . Loss:  0.00937159\n",
      "Step:  3200 . Loss:  0.0037049\n",
      "Step:  3300 . Loss:  0.00276002\n",
      "Step:  3400 . Loss:  0.0051864\n",
      "Step:  3500 . Loss:  0.00418616\n",
      "Step:  3600 . Loss:  0.00424947\n",
      "Step:  3700 . Loss:  0.00140348\n",
      "Step:  3800 . Loss:  0.00306774\n",
      "Step:  3900 . Loss:  0.00643148\n"
     ]
    }
   ],
   "source": [
    "for i in range(max_steps):\n",
    "    \n",
    "    train_batch = sess.run(train_input)\n",
    "    summary_str, _ = sess.run([summary_op, train_step], feed_dict={\n",
    "            X:train_batch[0], target_Class:train_batch[1], is_training: True})\n",
    "    summary_writer.add_summary(summary_str, i)    \n",
    "    if i % 100 == 0:\n",
    "        loss = sess.run(cross_entropy,feed_dict={X:train_batch[0], target_Class:train_batch[1], is_training: False})\n",
    "        print 'Step: ',i,'. Loss: ',loss\n",
    "        #if loss < 0.05 :\n",
    "        #    saver.save(sess, os.path.join(train_dir, 'Save/model.ckpt'))\n",
    "        #    break\n",
    "    if i % 1000 == 0 or (i + 1) == max_steps:\n",
    "        saver.save(sess, os.path.join(train_dir, 'Save/model.ckpt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.923357\n"
     ]
    }
   ],
   "source": [
    "val_batch = sess.run(val_input)\n",
    "acc = sess.run(accuracy, feed_dict={X: val_batch[0], target_Class:val_batch[1], is_training: False})\n",
    "print acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# No Regularization, lr = 1e-3 (4000 steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:  0 . Loss:  3.27126\n",
      "Step:  100 . Loss:  2.7425\n",
      "Step:  200 . Loss:  2.50846\n",
      "Step:  300 . Loss:  2.28948\n",
      "Step:  400 . Loss:  1.81827\n",
      "Step:  500 . Loss:  1.53847\n",
      "Step:  600 . Loss:  1.39143\n",
      "Step:  700 . Loss:  0.923713\n",
      "Step:  800 . Loss:  0.631433\n",
      "Step:  900 . Loss:  0.615287\n",
      "Step:  1000 . Loss:  0.40281\n",
      "Step:  1100 . Loss:  0.371273\n",
      "Step:  1200 . Loss:  0.18481\n",
      "Step:  1300 . Loss:  0.194823\n",
      "Step:  1400 . Loss:  0.122308\n",
      "Step:  1500 . Loss:  0.131396\n",
      "Step:  1600 . Loss:  0.0362113\n",
      "Step:  1700 . Loss:  0.0576668\n",
      "Step:  1800 . Loss:  0.028953\n",
      "Step:  1900 . Loss:  0.0317863\n",
      "Step:  2000 . Loss:  0.0239923\n",
      "Step:  2100 . Loss:  0.0127741\n",
      "Step:  2200 . Loss:  0.0102238\n",
      "Step:  2300 . Loss:  0.0169185\n",
      "Step:  2400 . Loss:  0.0164253\n",
      "Step:  2500 . Loss:  0.00831673\n",
      "Step:  2600 . Loss:  0.00916131\n",
      "Step:  2700 . Loss:  0.00656087\n",
      "Step:  2800 . Loss:  0.00431385\n",
      "Step:  2900 . Loss:  0.00348907\n",
      "Step:  3000 . Loss:  0.0031575\n",
      "Step:  3100 . Loss:  0.00428604\n",
      "Step:  3200 . Loss:  0.00215819\n",
      "Step:  3300 . Loss:  0.00429736\n",
      "Step:  3400 . Loss:  0.00420099\n",
      "Step:  3500 . Loss:  0.01164\n",
      "Step:  3600 . Loss:  0.00499621\n",
      "Step:  3700 . Loss:  0.00358696\n",
      "Step:  3800 . Loss:  0.00353252\n",
      "Step:  3900 . Loss:  0.00278925\n"
     ]
    }
   ],
   "source": [
    "for i in range(max_steps):\n",
    "    \n",
    "    train_batch = sess.run(train_input)\n",
    "    summary_str, _ = sess.run([summary_op, train_step], feed_dict={\n",
    "            X:train_batch[0], target_Class:train_batch[1], is_training: True})\n",
    "    summary_writer.add_summary(summary_str, i)    \n",
    "    if i % 100 == 0:\n",
    "        loss = sess.run(cross_entropy,feed_dict={X:train_batch[0], target_Class:train_batch[1], is_training: False})\n",
    "        print 'Step: ',i,'. Loss: ',loss\n",
    "        #if loss < 0.05 :\n",
    "        #    saver.save(sess, os.path.join(train_dir, 'Save/model.ckpt'))\n",
    "        #    break\n",
    "    if i % 1000 == 0 or (i + 1) == max_steps:\n",
    "        saver.save(sess, os.path.join(train_dir, 'Save/model.ckpt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.939509\n"
     ]
    }
   ],
   "source": [
    "val_batch = sess.run(val_input)\n",
    "acc = sess.run(accuracy, feed_dict={X: val_batch[0], target_Class:val_batch[1], is_training: False})\n",
    "print acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dropout = 0.5 (last layer), lr = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:  0 . Loss:  3.20708\n",
      "Step:  100 . Loss:  1.69797\n",
      "Step:  200 . Loss:  1.61656\n",
      "Step:  300 . Loss:  1.45878\n",
      "Step:  400 . Loss:  1.44049\n",
      "Step:  500 . Loss:  1.23969\n",
      "Step:  600 . Loss:  0.885668\n",
      "Step:  700 . Loss:  0.726471\n",
      "Step:  800 . Loss:  0.620086\n",
      "Step:  900 . Loss:  0.40522\n",
      "Step:  1000 . Loss:  0.260088\n",
      "Step:  1100 . Loss:  0.187275\n",
      "Step:  1200 . Loss:  0.233846\n",
      "Step:  1300 . Loss:  0.176295\n",
      "Step:  1400 . Loss:  0.162203\n",
      "Step:  1500 . Loss:  0.155508\n",
      "Step:  1600 . Loss:  0.11534\n",
      "Step:  1700 . Loss:  0.0846709\n",
      "Step:  1800 . Loss:  0.0832071\n",
      "Step:  1900 . Loss:  0.0597158\n"
     ]
    }
   ],
   "source": [
    "for i in range(max_steps):\n",
    "    \n",
    "    train_batch = sess.run(train_input)\n",
    "    summary_str, _ = sess.run([summary_op, train_step], feed_dict={\n",
    "            X:train_batch[0], target_Class:train_batch[1], is_training: True})\n",
    "    summary_writer.add_summary(summary_str, i)    \n",
    "    if i % 100 == 0:\n",
    "        loss = sess.run(cross_entropy,feed_dict={X:train_batch[0], target_Class:train_batch[1], is_training: False})\n",
    "        print 'Step: ',i,'. Loss: ',loss\n",
    "        #if loss < 0.05 :\n",
    "        #    saver.save(sess, os.path.join(train_dir, 'Save/model.ckpt'))\n",
    "        #    break\n",
    "    if i % 1000 == 0 or (i + 1) == max_steps:\n",
    "        saver.save(sess, os.path.join(train_dir, 'Save/model.ckpt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.907284\n"
     ]
    }
   ],
   "source": [
    "val_batch = sess.run(val_input)\n",
    "acc = sess.run(accuracy, feed_dict={X: val_batch[0], target_Class:val_batch[1], is_training: False})\n",
    "print acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dropout = 0.5 (middle layer), lr = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:  0 . Loss:  3.25864\n",
      "Step:  100 . Loss:  1.95356\n",
      "Step:  200 . Loss:  1.514\n",
      "Step:  300 . Loss:  1.18764\n",
      "Step:  400 . Loss:  0.956713\n",
      "Step:  500 . Loss:  0.746332\n",
      "Step:  600 . Loss:  0.546943\n",
      "Step:  700 . Loss:  0.408633\n",
      "Step:  800 . Loss:  0.365197\n",
      "Step:  900 . Loss:  0.198042\n",
      "Step:  1000 . Loss:  0.205343\n",
      "Step:  1100 . Loss:  0.210917\n",
      "Step:  1200 . Loss:  0.171875\n",
      "Step:  1300 . Loss:  0.126247\n",
      "Step:  1400 . Loss:  0.107294\n",
      "Step:  1500 . Loss:  0.115601\n",
      "Step:  1600 . Loss:  0.0430274\n",
      "Step:  1700 . Loss:  0.0559825\n",
      "Step:  1800 . Loss:  0.0376206\n",
      "Step:  1900 . Loss:  0.0573068\n"
     ]
    }
   ],
   "source": [
    "for i in range(max_steps):\n",
    "    \n",
    "    train_batch = sess.run(train_input)\n",
    "    summary_str, _ = sess.run([summary_op, train_step], feed_dict={\n",
    "            X:train_batch[0], target_Class:train_batch[1], is_training: True})\n",
    "    summary_writer.add_summary(summary_str, i)    \n",
    "    if i % 100 == 0:\n",
    "        loss = sess.run(cross_entropy,feed_dict={X:train_batch[0], target_Class:train_batch[1], is_training: False})\n",
    "        print 'Step: ',i,'. Loss: ',loss\n",
    "        #if loss < 0.05 :\n",
    "        #    saver.save(sess, os.path.join(train_dir, 'Save/model.ckpt'))\n",
    "        #    break\n",
    "    if i % 1000 == 0 or (i + 1) == max_steps:\n",
    "        saver.save(sess, os.path.join(train_dir, 'Save/model.ckpt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.907601\n"
     ]
    }
   ],
   "source": [
    "val_batch = sess.run(val_input)\n",
    "acc = sess.run(accuracy, feed_dict={X: val_batch[0], target_Class:val_batch[1], is_training: False})\n",
    "print acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dropout = 0.5 (middle layer), lr = 5e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:  0 . Loss:  6.27248\n",
      "Step:  100 . Loss:  4.33184\n",
      "Step:  200 . Loss:  1.61654\n",
      "Step:  300 . Loss:  1.03965\n",
      "Step:  400 . Loss:  1.34462\n",
      "Step:  500 . Loss:  0.595149\n",
      "Step:  600 . Loss:  0.436976\n",
      "Step:  700 . Loss:  0.479226\n",
      "Step:  800 . Loss:  0.295557\n",
      "Step:  900 . Loss:  0.728844\n",
      "Step:  1000 . Loss:  0.375222\n",
      "Step:  1100 . Loss:  0.303997\n",
      "Step:  1200 . Loss:  0.289826\n",
      "Step:  1300 . Loss:  0.228252\n",
      "Step:  1400 . Loss:  0.507276\n",
      "Step:  1500 . Loss:  0.134793\n",
      "Step:  1600 . Loss:  0.103756\n",
      "Step:  1700 . Loss:  0.484255\n",
      "Step:  1800 . Loss:  0.225907\n",
      "Step:  1900 . Loss:  0.142048\n"
     ]
    }
   ],
   "source": [
    "for i in range(max_steps):\n",
    "    \n",
    "    train_batch = sess.run(train_input)\n",
    "    summary_str, _ = sess.run([summary_op, train_step], feed_dict={\n",
    "            X:train_batch[0], target_Class:train_batch[1], is_training: True})\n",
    "    summary_writer.add_summary(summary_str, i)    \n",
    "    if i % 100 == 0:\n",
    "        loss = sess.run(cross_entropy,feed_dict={X:train_batch[0], target_Class:train_batch[1], is_training: False})\n",
    "        print 'Step: ',i,'. Loss: ',loss\n",
    "        #if loss < 0.05 :\n",
    "        #    saver.save(sess, os.path.join(train_dir, 'Save/model.ckpt'))\n",
    "        #    break\n",
    "    if i % 1000 == 0 or (i + 1) == max_steps:\n",
    "        saver.save(sess, os.path.join(train_dir, 'Save/model.ckpt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.875772\n"
     ]
    }
   ],
   "source": [
    "val_batch = sess.run(val_input)\n",
    "acc = sess.run(accuracy, feed_dict={X: val_batch[0], target_Class:val_batch[1], is_training: False})\n",
    "print acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hinge Loss without Regularization (lr = 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:  0 . Loss:  0.118169 Accuracy:  0.0159145\n",
      "Step:  100 . Loss:  0.0994305 Accuracy:  0.122328\n",
      "Step:  200 . Loss:  0.0567423 Accuracy:  0.409026\n",
      "Step:  300 . Loss:  0.0495981 Accuracy:  0.571338\n",
      "Step:  400 . Loss:  0.10735 Accuracy:  0.71639\n",
      "Step:  500 . Loss:  0.120744 Accuracy:  0.787569\n",
      "Step:  600 . Loss:  0.103508 Accuracy:  0.83753\n",
      "Step:  700 . Loss:  0.105103 Accuracy:  0.83175\n",
      "Step:  800 . Loss:  0.0559446 Accuracy:  0.855344\n",
      "Step:  900 . Loss:  0.054427 Accuracy:  0.866588\n",
      "Step:  1000 . Loss:  0.043141 Accuracy:  0.869438\n",
      "Step:  1100 . Loss:  0.0483084 Accuracy:  0.888836\n",
      "Step:  1200 . Loss:  0.013869 Accuracy:  0.883848\n",
      "Step:  1300 . Loss:  0.0210285 Accuracy:  0.90285\n",
      "Step:  1400 . Loss:  0.00999276 Accuracy:  0.912589\n",
      "Step:  1500 . Loss:  0.00630162 Accuracy:  0.905463\n",
      "Step:  1600 . Loss:  0.0113905 Accuracy:  0.917498\n",
      "Step:  1700 . Loss:  0.00427542 Accuracy:  0.913143\n",
      "Step:  1800 . Loss:  0.00482325 Accuracy:  0.922011\n",
      "Step:  1900 . Loss:  0.00702487 Accuracy:  0.925336\n"
     ]
    }
   ],
   "source": [
    "for i in range(max_steps):\n",
    "    \n",
    "    train_batch = sess.run(train_input)\n",
    "    summary_str, _ = sess.run([summary_op, train_step], feed_dict={\n",
    "            X:train_batch[0], target_Class:train_batch[1], is_training: True})\n",
    "    summary_writer.add_summary(summary_str, i)    \n",
    "    if i % 100 == 0:\n",
    "        \n",
    "        acc = sess.run(accuracy, feed_dict={X: val_batch[0], target_Class:val_batch[1], is_training: False})\n",
    "        \n",
    "        loss = sess.run(final_loss,feed_dict={X:train_batch[0], target_Class:train_batch[1], is_training: False})\n",
    "        print 'Step: ',i,'. Loss: ',loss,'Accuracy: ',acc\n",
    "        \n",
    "        #if loss < 0.05 :\n",
    "        #    saver.save(sess, os.path.join(train_dir, 'Save/model.ckpt'))\n",
    "        #    break\n",
    "    if i % 1000 == 0 or (i + 1) == max_steps:\n",
    "        saver.save(sess, os.path.join(train_dir, 'Save/model.ckpt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.921774\n"
     ]
    }
   ],
   "source": [
    "val_batch = sess.run(val_input)\n",
    "acc = sess.run(accuracy, feed_dict={X: val_batch[0], target_Class:val_batch[1], is_training: False})\n",
    "print acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hinge Loss with Regularization on all layers (lr = 1e-3, lambda = 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:  0 . Loss:  0.122106 Accuracy:  0.0214568\n",
      "Step:  100 . Loss:  0.0800602 Accuracy:  0.200871\n",
      "Step:  200 . Loss:  0.127177 Accuracy:  0.397229\n",
      "Step:  300 . Loss:  0.369744 Accuracy:  0.620823\n",
      "Step:  400 . Loss:  0.367617 Accuracy:  0.754869\n",
      "Step:  500 . Loss:  0.342103 Accuracy:  0.78361\n",
      "Step:  600 . Loss:  0.398549 Accuracy:  0.836184\n",
      "Step:  700 . Loss:  0.310535 Accuracy:  0.847981\n",
      "Step:  800 . Loss:  0.312676 Accuracy:  0.868329\n",
      "Step:  900 . Loss:  0.280864 Accuracy:  0.858512\n",
      "Step:  1000 . Loss:  0.263061 Accuracy:  0.883769\n",
      "Step:  1100 . Loss:  0.158154 Accuracy:  0.895091\n",
      "Step:  1200 . Loss:  0.116719 Accuracy:  0.895804\n",
      "Step:  1300 . Loss:  0.0835526 Accuracy:  0.914252\n",
      "Step:  1400 . Loss:  0.0654995 Accuracy:  0.906968\n",
      "Step:  1500 . Loss:  0.0589969 Accuracy:  0.907363\n",
      "Step:  1600 . Loss:  0.0648629 Accuracy:  0.909264\n",
      "Step:  1700 . Loss:  0.030619 Accuracy:  0.920348\n",
      "Step:  1800 . Loss:  0.0373643 Accuracy:  0.91829\n",
      "Step:  1900 . Loss:  0.0243933 Accuracy:  0.921457\n"
     ]
    }
   ],
   "source": [
    "for i in range(max_steps):\n",
    "    \n",
    "    train_batch = sess.run(train_input)\n",
    "    summary_str, _ = sess.run([summary_op, train_step], feed_dict={\n",
    "            X:train_batch[0], target_Class:train_batch[1], is_training: True})\n",
    "    summary_writer.add_summary(summary_str, i)    \n",
    "    if i % 100 == 0:\n",
    "        \n",
    "        acc = sess.run(accuracy, feed_dict={X: val_batch[0], target_Class:val_batch[1], is_training: False})\n",
    "        \n",
    "        loss = sess.run(final_loss,feed_dict={X:train_batch[0], target_Class:train_batch[1], is_training: False})\n",
    "        print 'Step: ',i,'. Loss: ',loss,'Accuracy: ',acc\n",
    "        \n",
    "        #if loss < 0.05 :\n",
    "        #    saver.save(sess, os.path.join(train_dir, 'Save/model.ckpt'))\n",
    "        #    break\n",
    "    if i % 1000 == 0 or (i + 1) == max_steps:\n",
    "        saver.save(sess, os.path.join(train_dir, 'Save/model.ckpt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.916152\n"
     ]
    }
   ],
   "source": [
    "val_batch = sess.run(val_input)\n",
    "acc = sess.run(accuracy, feed_dict={X: val_batch[0], target_Class:val_batch[1], is_training: False})\n",
    "print acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hinge Loss with Regularization on only fully connected layer (lr = 1e-3, lambda = 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:  0 . Loss:  0.115071\n",
      "Step:  100 . Loss:  0.100509\n",
      "Step:  200 . Loss:  0.0520454\n",
      "Step:  300 . Loss:  0.0529256\n",
      "Step:  400 . Loss:  0.0978769\n",
      "Step:  500 . Loss:  0.122575\n",
      "Step:  600 . Loss:  0.104214\n",
      "Step:  700 . Loss:  0.0671537\n",
      "Step:  800 . Loss:  0.0441727\n",
      "Step:  900 . Loss:  0.0564359\n",
      "Step:  1000 . Loss:  0.035203\n",
      "Step:  1100 . Loss:  0.0211783\n",
      "Step:  1200 . Loss:  0.0203727\n",
      "Step:  1300 . Loss:  0.0160817\n",
      "Step:  1400 . Loss:  0.0113473\n",
      "Step:  1500 . Loss:  0.00701093\n",
      "Step:  1600 . Loss:  0.00690741\n",
      "Step:  1700 . Loss:  0.00659867\n",
      "Step:  1800 . Loss:  0.00686619\n",
      "Step:  1900 . Loss:  0.00477867\n"
     ]
    }
   ],
   "source": [
    "for i in range(max_steps):\n",
    "    \n",
    "    train_batch = sess.run(train_input)\n",
    "    summary_str, _ = sess.run([summary_op, train_step], feed_dict={\n",
    "            X:train_batch[0], target_Class:train_batch[1], is_training: True})\n",
    "    summary_writer.add_summary(summary_str, i)    \n",
    "    if i % 100 == 0:\n",
    "        loss = sess.run(final_loss,feed_dict={X:train_batch[0], target_Class:train_batch[1], is_training: False})\n",
    "        print 'Step: ',i,'. Loss: ',loss\n",
    "        \n",
    "        #if loss < 0.05 :\n",
    "        #    saver.save(sess, os.path.join(train_dir, 'Save/model.ckpt'))\n",
    "        #    break\n",
    "    if i % 1000 == 0 or (i + 1) == max_steps:\n",
    "        saver.save(sess, os.path.join(train_dir, 'Save/model.ckpt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.918369\n"
     ]
    }
   ],
   "source": [
    "val_batch = sess.run(val_input)\n",
    "acc = sess.run(accuracy, feed_dict={X: val_batch[0], target_Class:val_batch[1], is_training: False})\n",
    "print acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hinge Loss with Regularization on all layer (lr = 1e-3, lambda = 5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:  0 . Loss:  0.156111\n",
      "Step:  100 . Loss:  0.089378\n",
      "Step:  200 . Loss:  0.0535664\n",
      "Step:  300 . Loss:  0.149591\n",
      "Step:  400 . Loss:  0.173702\n",
      "Step:  500 . Loss:  0.25296\n",
      "Step:  600 . Loss:  0.207785\n",
      "Step:  700 . Loss:  0.172098\n",
      "Step:  800 . Loss:  0.113136\n",
      "Step:  900 . Loss:  0.0956571\n",
      "Step:  1000 . Loss:  0.0488638\n",
      "Step:  1100 . Loss:  0.0508386\n",
      "Step:  1200 . Loss:  0.0342766\n",
      "Step:  1300 . Loss:  0.0285713\n",
      "Step:  1400 . Loss:  0.0196951\n",
      "Step:  1500 . Loss:  0.0185723\n",
      "Step:  1600 . Loss:  0.0170751\n",
      "Step:  1700 . Loss:  0.00995203\n",
      "Step:  1800 . Loss:  0.0114049\n",
      "Step:  1900 . Loss:  0.0129062\n"
     ]
    }
   ],
   "source": [
    "for i in range(max_steps):\n",
    "    \n",
    "    train_batch = sess.run(train_input)\n",
    "    summary_str, _ = sess.run([summary_op, train_step], feed_dict={\n",
    "            X:train_batch[0], target_Class:train_batch[1], is_training: True})\n",
    "    summary_writer.add_summary(summary_str, i)    \n",
    "    if i % 100 == 0:\n",
    "        loss = sess.run(final_loss,feed_dict={X:train_batch[0], target_Class:train_batch[1], is_training: False})\n",
    "        print 'Step: ',i,'. Loss: ',loss\n",
    "        \n",
    "        #if loss < 0.05 :\n",
    "        #    saver.save(sess, os.path.join(train_dir, 'Save/model.ckpt'))\n",
    "        #    break\n",
    "    if i % 1000 == 0 or (i + 1) == max_steps:\n",
    "        saver.save(sess, os.path.join(train_dir, 'Save/model.ckpt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.933333\n"
     ]
    }
   ],
   "source": [
    "val_batch = sess.run(val_input)\n",
    "acc = sess.run(accuracy, feed_dict={X: val_batch[0], target_Class:val_batch[1], is_training: False})\n",
    "print acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hinge Loss with Regularization on only fully connected layer (lr = 1e-3, lambda = 5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:  0 . Loss:  0.230314\n",
      "Step:  100 . Loss:  0.106894\n",
      "Step:  200 . Loss:  0.637119\n",
      "Step:  300 . Loss:  0.90321\n",
      "Step:  400 . Loss:  1.02441\n",
      "Step:  500 . Loss:  1.06069\n",
      "Step:  600 . Loss:  0.995734\n",
      "Step:  700 . Loss:  1.00458\n",
      "Step:  800 . Loss:  0.904947\n",
      "Step:  900 . Loss:  0.864348\n",
      "Step:  1000 . Loss:  0.806455\n",
      "Step:  1100 . Loss:  0.716547\n",
      "Step:  1200 . Loss:  0.643991\n",
      "Step:  1300 . Loss:  0.660114\n",
      "Step:  1400 . Loss:  0.549792\n",
      "Step:  1500 . Loss:  0.520844\n",
      "Step:  1600 . Loss:  0.493345\n",
      "Step:  1700 . Loss:  0.437093\n",
      "Step:  1800 . Loss:  0.384636\n",
      "Step:  1900 . Loss:  0.242769\n"
     ]
    }
   ],
   "source": [
    "for i in range(max_steps):\n",
    "    \n",
    "    train_batch = sess.run(train_input)\n",
    "    summary_str, _ = sess.run([summary_op, train_step], feed_dict={\n",
    "            X:train_batch[0], target_Class:train_batch[1], is_training: True})\n",
    "    summary_writer.add_summary(summary_str, i)    \n",
    "    if i % 100 == 0:\n",
    "        loss = sess.run(final_loss,feed_dict={X:train_batch[0], target_Class:train_batch[1], is_training: False})\n",
    "        print 'Step: ',i,'. Loss: ',loss\n",
    "        \n",
    "        #if loss < 0.05 :\n",
    "        #    saver.save(sess, os.path.join(train_dir, 'Save/model.ckpt'))\n",
    "        #    break\n",
    "    if i % 1000 == 0 or (i + 1) == max_steps:\n",
    "        saver.save(sess, os.path.join(train_dir, 'Save/model.ckpt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.882502\n"
     ]
    }
   ],
   "source": [
    "val_batch = sess.run(val_input)\n",
    "acc = sess.run(accuracy, feed_dict={X: val_batch[0], target_Class:val_batch[1], is_training: False})\n",
    "print acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hinge Loss no Regularization (lr = 5e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:  0 . Loss:  0.185806\n",
      "Step:  100 . Loss:  0.854869\n",
      "Step:  200 . Loss:  0.266195\n",
      "Step:  300 . Loss:  0.114137\n",
      "Step:  400 . Loss:  0.0691381\n",
      "Step:  500 . Loss:  0.0463314\n",
      "Step:  600 . Loss:  0.0290599\n",
      "Step:  700 . Loss:  0.0236223\n",
      "Step:  800 . Loss:  0.015579\n",
      "Step:  900 . Loss:  0.0178797\n",
      "Step:  1000 . Loss:  0.0253953\n",
      "Step:  1100 . Loss:  0.0246214\n",
      "Step:  1200 . Loss:  0.00992134\n",
      "Step:  1300 . Loss:  0.00929281\n",
      "Step:  1400 . Loss:  0.00473579\n",
      "Step:  1500 . Loss:  0.0116638\n",
      "Step:  1600 . Loss:  0.006737\n",
      "Step:  1700 . Loss:  0.00554582\n",
      "Step:  1800 . Loss:  0.00400493\n",
      "Step:  1900 . Loss:  0.00270115\n"
     ]
    }
   ],
   "source": [
    "for i in range(max_steps):\n",
    "    \n",
    "    train_batch = sess.run(train_input)\n",
    "    summary_str, _ = sess.run([summary_op, train_step], feed_dict={\n",
    "            X:train_batch[0], target_Class:train_batch[1], is_training: True})\n",
    "    summary_writer.add_summary(summary_str, i)    \n",
    "    if i % 100 == 0:\n",
    "        loss = sess.run(final_loss,feed_dict={X:train_batch[0], target_Class:train_batch[1], is_training: False})\n",
    "        print 'Step: ',i,'. Loss: ',loss\n",
    "        \n",
    "        #if loss < 0.05 :\n",
    "        #    saver.save(sess, os.path.join(train_dir, 'Save/model.ckpt'))\n",
    "        #    break\n",
    "    if i % 1000 == 0 or (i + 1) == max_steps:\n",
    "        saver.save(sess, os.path.join(train_dir, 'Save/model.ckpt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.924941\n"
     ]
    }
   ],
   "source": [
    "val_batch = sess.run(val_input)\n",
    "acc = sess.run(accuracy, feed_dict={X: val_batch[0], target_Class:val_batch[1], is_training: False})\n",
    "print acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hinge Loss with Regularization on fully connected parameters (lr = 5e-3, lambda = 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:  0 . Loss:  0.212878\n",
      "Step:  100 . Loss:  0.685353\n",
      "Step:  200 . Loss:  0.23407\n",
      "Step:  300 . Loss:  0.0733275\n",
      "Step:  400 . Loss:  0.0255754\n",
      "Step:  500 . Loss:  0.0221241\n",
      "Step:  600 . Loss:  0.0172838\n",
      "Step:  700 . Loss:  0.016853\n",
      "Step:  800 . Loss:  0.0178172\n",
      "Step:  900 . Loss:  0.0107884\n",
      "Step:  1000 . Loss:  0.0082546\n",
      "Step:  1100 . Loss:  0.012205\n",
      "Step:  1200 . Loss:  0.00869569\n",
      "Step:  1300 . Loss:  0.00682247\n",
      "Step:  1400 . Loss:  0.00980327\n",
      "Step:  1500 . Loss:  0.0129191\n",
      "Step:  1600 . Loss:  0.00732039\n",
      "Step:  1700 . Loss:  0.00733274\n",
      "Step:  1800 . Loss:  0.0048902\n",
      "Step:  1900 . Loss:  0.00707775\n"
     ]
    }
   ],
   "source": [
    "for i in range(max_steps):\n",
    "    \n",
    "    train_batch = sess.run(train_input)\n",
    "    summary_str, _ = sess.run([summary_op, train_step], feed_dict={\n",
    "            X:train_batch[0], target_Class:train_batch[1], is_training: True})\n",
    "    summary_writer.add_summary(summary_str, i)    \n",
    "    if i % 100 == 0:\n",
    "        loss = sess.run(final_loss,feed_dict={X:train_batch[0], target_Class:train_batch[1], is_training: False})\n",
    "        print 'Step: ',i,'. Loss: ',loss\n",
    "        \n",
    "        #if loss < 0.05 :\n",
    "        #    saver.save(sess, os.path.join(train_dir, 'Save/model.ckpt'))\n",
    "        #    break\n",
    "    if i % 1000 == 0 or (i + 1) == max_steps:\n",
    "        saver.save(sess, os.path.join(train_dir, 'Save/model.ckpt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.933175\n"
     ]
    }
   ],
   "source": [
    "val_batch = sess.run(val_input)\n",
    "acc = sess.run(accuracy, feed_dict={X: val_batch[0], target_Class:val_batch[1], is_training: False})\n",
    "print acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hinge Loss with Regularization on all parameters (lr = 5e-3, lambda = 5e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:  0 . Loss:  0.279055\n",
      "Step:  100 . Loss:  0.219018\n",
      "Step:  200 . Loss:  0.786828\n",
      "Step:  300 . Loss:  0.989573\n",
      "Step:  400 . Loss:  1.02419\n",
      "Step:  500 . Loss:  0.60585\n",
      "Step:  600 . Loss:  0.558758\n",
      "Step:  700 . Loss:  0.439166\n",
      "Step:  800 . Loss:  0.368158\n",
      "Step:  900 . Loss:  0.2629\n",
      "Step:  1000 . Loss:  0.262154\n",
      "Step:  1100 . Loss:  0.18949\n",
      "Step:  1200 . Loss:  0.227115\n",
      "Step:  1300 . Loss:  0.404901\n",
      "Step:  1400 . Loss:  0.250201\n",
      "Step:  1500 . Loss:  0.0748346\n",
      "Step:  1600 . Loss:  0.0968797\n",
      "Step:  1700 . Loss:  0.106577\n",
      "Step:  1800 . Loss:  0.0957323\n",
      "Step:  1900 . Loss:  0.0864901\n"
     ]
    }
   ],
   "source": [
    "for i in range(max_steps):\n",
    "    \n",
    "    train_batch = sess.run(train_input)\n",
    "    summary_str, _ = sess.run([summary_op, train_step], feed_dict={\n",
    "            X:train_batch[0], target_Class:train_batch[1], is_training: True})\n",
    "    summary_writer.add_summary(summary_str, i)    \n",
    "    if i % 100 == 0:\n",
    "        loss = sess.run(final_loss,feed_dict={X:train_batch[0], target_Class:train_batch[1], is_training: False})\n",
    "        print 'Step: ',i,'. Loss: ',loss\n",
    "        \n",
    "        #if loss < 0.05 :\n",
    "        #    saver.save(sess, os.path.join(train_dir, 'Save/model.ckpt'))\n",
    "        #    break\n",
    "    if i % 1000 == 0 or (i + 1) == max_steps:\n",
    "        saver.save(sess, os.path.join(train_dir, 'Save/model.ckpt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.775376\n"
     ]
    }
   ],
   "source": [
    "val_batch = sess.run(val_input)\n",
    "acc = sess.run(accuracy, feed_dict={X: val_batch[0], target_Class:val_batch[1], is_training: False})\n",
    "print acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hinge Loss with Regularization on all parameters (lr = 5e-3, lambda = 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:  0 . Loss:  0.195729\n",
      "Step:  100 . Loss:  0.67274\n",
      "Step:  200 . Loss:  0.122922\n",
      "Step:  300 . Loss:  0.0522099\n",
      "Step:  400 . Loss:  0.0595671\n",
      "Step:  500 . Loss:  0.0419748\n",
      "Step:  600 . Loss:  0.0612903\n",
      "Step:  700 . Loss:  0.0343615\n",
      "Step:  800 . Loss:  0.0514625\n",
      "Step:  900 . Loss:  0.0261861\n",
      "Step:  1000 . Loss:  0.032759\n",
      "Step:  1100 . Loss:  0.0244642\n",
      "Step:  1200 . Loss:  0.0251186\n",
      "Step:  1300 . Loss:  0.0219984\n",
      "Step:  1400 . Loss:  0.0227893\n",
      "Step:  1500 . Loss:  0.017236\n",
      "Step:  1600 . Loss:  0.0215277\n",
      "Step:  1700 . Loss:  0.018411\n",
      "Step:  1800 . Loss:  0.0205493\n",
      "Step:  1900 . Loss:  0.0188811\n"
     ]
    }
   ],
   "source": [
    "for i in range(max_steps):\n",
    "    \n",
    "    train_batch = sess.run(train_input)\n",
    "    summary_str, _ = sess.run([summary_op, train_step], feed_dict={\n",
    "            X:train_batch[0], target_Class:train_batch[1], is_training: True})\n",
    "    summary_writer.add_summary(summary_str, i)    \n",
    "    if i % 100 == 0:\n",
    "        loss = sess.run(final_loss,feed_dict={X:train_batch[0], target_Class:train_batch[1], is_training: False})\n",
    "        print 'Step: ',i,'. Loss: ',loss\n",
    "        \n",
    "        #if loss < 0.05 :\n",
    "        #    saver.save(sess, os.path.join(train_dir, 'Save/model.ckpt'))\n",
    "        #    break\n",
    "    if i % 1000 == 0 or (i + 1) == max_steps:\n",
    "        saver.save(sess, os.path.join(train_dir, 'Save/model.ckpt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.870467\n"
     ]
    }
   ],
   "source": [
    "val_batch = sess.run(val_input)\n",
    "acc = sess.run(accuracy, feed_dict={X: val_batch[0], target_Class:val_batch[1], is_training: False})\n",
    "print acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hinge Loss with Regularization on fully connected parameters (lr = 5e-3, lambda = 5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:  0 . Loss:  0.167912\n",
      "Step:  100 . Loss:  0.4594\n",
      "Step:  200 . Loss:  0.164285\n",
      "Step:  300 . Loss:  0.0625068\n",
      "Step:  400 . Loss:  0.0285088\n",
      "Step:  500 . Loss:  0.0248637\n",
      "Step:  600 . Loss:  0.0209271\n",
      "Step:  700 . Loss:  0.0252341\n",
      "Step:  800 . Loss:  0.0194386\n",
      "Step:  900 . Loss:  0.0139315\n",
      "Step:  1000 . Loss:  0.0194199\n",
      "Step:  1100 . Loss:  0.018275\n",
      "Step:  1200 . Loss:  0.0114665\n",
      "Step:  1300 . Loss:  0.0111969\n",
      "Step:  1400 . Loss:  0.0144521\n",
      "Step:  1500 . Loss:  0.0114778\n",
      "Step:  1600 . Loss:  0.013318\n",
      "Step:  1700 . Loss:  0.00992228\n",
      "Step:  1800 . Loss:  0.00800235\n",
      "Step:  1900 . Loss:  0.008207\n"
     ]
    }
   ],
   "source": [
    "for i in range(max_steps):\n",
    "    \n",
    "    train_batch = sess.run(train_input)\n",
    "    summary_str, _ = sess.run([summary_op, train_step], feed_dict={\n",
    "            X:train_batch[0], target_Class:train_batch[1], is_training: True})\n",
    "    summary_writer.add_summary(summary_str, i)    \n",
    "    if i % 100 == 0:\n",
    "        loss = sess.run(final_loss,feed_dict={X:train_batch[0], target_Class:train_batch[1], is_training: False})\n",
    "        print 'Step: ',i,'. Loss: ',loss\n",
    "        \n",
    "        #if loss < 0.05 :\n",
    "        #    saver.save(sess, os.path.join(train_dir, 'Save/model.ckpt'))\n",
    "        #    break\n",
    "    if i % 1000 == 0 or (i + 1) == max_steps:\n",
    "        saver.save(sess, os.path.join(train_dir, 'Save/model.ckpt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.922249\n"
     ]
    }
   ],
   "source": [
    "val_batch = sess.run(val_input)\n",
    "acc = sess.run(accuracy, feed_dict={X: val_batch[0], target_Class:val_batch[1], is_training: False})\n",
    "print acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:anaconda]",
   "language": "python",
   "name": "conda-env-anaconda-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
